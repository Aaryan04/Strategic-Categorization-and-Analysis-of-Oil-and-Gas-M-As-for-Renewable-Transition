{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset to inspect its structure and contents\n",
    "file_path = '/Users/aaryanshah/Oncampus-Job/NLP_Gal/data/TrainingSet 1(Deals).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe and its general information\n",
    "data.head(), data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where key text columns have missing values\n",
    "data_clean = data.dropna(subset=['Target Business Description', 'M&A Headline', 'Deal Synopsis'])\n",
    "\n",
    "# Combining the three text columns into one\n",
    "data_clean['Combined Text'] = data_clean['Target Business Description'] + \" \" + \\\n",
    "                              data_clean['M&A Headline'] + \" \" + data_clean['Deal Synopsis']\n",
    "\n",
    "# Inspecting the first few rows of the combined text and the human ratings columns\n",
    "data_clean[['Combined Text', 'Singh', 'Arora', 'Neilsen', 'RH', 'Uche', 'Edrick']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to apply Leave-One-Out Cross-Validation method for bias reduction\n",
    "def leave_one_out_avg(row):\n",
    "    ratings = row[['Singh', 'Arora', 'Neilsen', 'RH', 'Uche', 'Edrick']]\n",
    "    loo_averages = []\n",
    "    # Remove one rating at a time and compute the mean of the rest\n",
    "    for i in range(len(ratings)):\n",
    "        loo_averages.append(np.mean(np.delete(ratings.values, i)))\n",
    "    return np.mean(loo_averages)  # Average of all LOO averages for final target\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "data_clean['Adjusted Rating'] = data_clean.apply(leave_one_out_avg, axis=1)\n",
    "\n",
    "# Show the first few rows of the adjusted ratings to verify\n",
    "data_clean[['Combined Text', 'Adjusted Rating']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map the adjusted ratings into the defined categories\n",
    "def map_rating_to_category(rating):\n",
    "    if rating < 1.5:\n",
    "        return 1  # Maintain Core Capabilities\n",
    "    elif rating < 2.5:\n",
    "        return 2  # Support Core Capabilities\n",
    "    elif rating < 3.5:\n",
    "        return 3  # Adjacent Capabilities\n",
    "    elif rating < 4.5:\n",
    "        return 4  # Near-Emergent Capabilities\n",
    "    else:\n",
    "        return 5  # Emergent Capabilities/Unrelated Diversification\n",
    "\n",
    "# Map the continuous adjusted ratings to discrete categories\n",
    "data_clean['Category'] = data_clean['Adjusted Rating'].apply(map_rating_to_category)\n",
    "\n",
    "# Show the distribution of the final categories\n",
    "category_distribution = data_clean['Category'].value_counts()\n",
    "\n",
    "# Displaying the first few rows with the mapped categories and the distribution of categories\n",
    "data_clean[['Combined Text', 'Adjusted Rating', 'Category']].head(), category_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Category 1: 1111 entries\n",
    "- Category 2: 592 entries\n",
    "- Category 3: 504 entries\n",
    "- Category 4: 202 entries\n",
    "- Category 5: 123 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Fit and transform the 'Combined Text' column\n",
    "X_tfidf = tfidf.fit_transform(data_clean['Combined Text'])\n",
    "\n",
    "# Extracting the target labels\n",
    "y = data_clean['Category']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the shape of the training and testing data\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the RandomForest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the RandomForest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_report = classification_report(y_test, rf_predictions)\n",
    "\n",
    "print('accuracy:',rf_accuracy) \n",
    "print('Classification Report:\\n', rf_report) # rf_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Splitting indices of the dataset into training and testing sets\n",
    "# train_indices, test_indices = train_test_split(data_clean.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Using the indices to access the text directly from the DataFrame for BERT\n",
    "# train_texts = data_clean.loc[train_indices, 'Combined Text'].tolist()\n",
    "# test_texts = data_clean.loc[test_indices, 'Combined Text'].tolist()\n",
    "\n",
    "# # Proceed with tokenization and dataset preparation as before\n",
    "# train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "# test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# # Your label data also needs to be accessed via indices\n",
    "# train_labels = data_clean.loc[train_indices, 'Category'].tolist()\n",
    "# test_labels = data_clean.loc[test_indices, 'Category'].tolist()\n",
    "\n",
    "# # Then, create your dataset for training and testing\n",
    "# train_dataset = DealsDataset(train_encodings, train_labels)\n",
    "# test_dataset = DealsDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer\n",
    "\n",
    "class DealsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting indices of the dataset into training and testing sets\n",
    "train_indices, test_indices = train_test_split(data_clean.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Using the indices to access the text directly from the DataFrame for BERT\n",
    "train_texts = data_clean.loc[train_indices, 'Combined Text'].tolist()\n",
    "test_texts = data_clean.loc[test_indices, 'Combined Text'].tolist()\n",
    "\n",
    "# Proceed with tokenization and dataset preparation as before\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Your label data also needs to be accessed via indices\n",
    "train_labels = data_clean.loc[train_indices, 'Category'].tolist()\n",
    "test_labels = data_clean.loc[test_indices, 'Category'].tolist()\n",
    "\n",
    "# Then, create your dataset for training and testing\n",
    "train_dataset = DealsDataset(train_encodings, train_labels)\n",
    "test_dataset = DealsDataset(test_encodings, test_labels)\n",
    "\n",
    "# Training arguments for BERT\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset            # evaluation dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(results)\n",
    "\n",
    "# If you need to calculate more detailed metrics manually:\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predicting on the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset.labels, pred_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(test_dataset.labels, pred_labels)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Count Vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit and transform the 'Combined Text' column\n",
    "X_count = count_vectorizer.fit_transform(data_clean['Combined Text'])\n",
    "\n",
    "# Splitting the dataset into training and testing sets using the count vectorized data\n",
    "X_train_count, X_test_count, y_train_count, y_test_count = train_test_split(\n",
    "    X_count, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(X_train_count, y_train_count)\n",
    "\n",
    "# Predict on the test set\n",
    "count_predictions = logreg_model.predict(X_test_count)\n",
    "\n",
    "# Evaluate the model\n",
    "count_accuracy = accuracy_score(y_test_count, count_predictions)\n",
    "count_report = classification_report(y_test_count, count_predictions)\n",
    "\n",
    "print('accuracy:', count_accuracy) # count_accuracy\n",
    "print('Classification Report:\\n', count_report) # count_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data_clean['Combined Text'])\n",
    "y = data_clean['Category']\n",
    "\n",
    "# Split the dataset\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    predictions = model.predict(X_test_tfidf)\n",
    "    print(f\"{name} with TF-IDF:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_tfidf, predictions))\n",
    "    print(classification_report(y_test_tfidf, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize TF-IDF\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_tfidf = count_vectorizer.fit_transform(data_clean['Combined Text'])\n",
    "y = data_clean['Category']\n",
    "\n",
    "# Split the dataset\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    predictions = model.predict(X_test_tfidf)\n",
    "    print(f\"{name} with Count Vectorizer:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_tfidf, predictions))\n",
    "    print(classification_report(y_test_tfidf, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertModel, BertTokenizer\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# def get_bert_embeddings(texts):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#         outputs = model(**inputs)\n",
    "#         embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # Taking the output of the [CLS] token\n",
    "#     return embeddings\n",
    "\n",
    "# # Example usage\n",
    "# texts = data_clean['Combined Text'].tolist()\n",
    "# bert_embeddings = get_bert_embeddings(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assume `bert_embeddings` is already prepared and `data['Category']` is the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, data_clean['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assume `bert_embeddings` is already prepared and `data['Category']` is the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, data_clean['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assume `bert_embeddings` is already prepared and `data['Category']` is the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, data_clean['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Assuming texts are already tokenized\n",
    "tokenized_texts = [text.split() for text in data_clean['Combined Text']]\n",
    "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_w2v_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        word_vectors = [w2v_model.wv[word] for word in text.split() if word in w2v_model.wv]\n",
    "        if word_vectors:\n",
    "            embeddings.append(np.mean(word_vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(100))  # Assuming vector_size=100\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Example usage\n",
    "w2v_embeddings = get_w2v_embeddings(data_clean['Combined Text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DealsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting indices of the dataset into training and testing sets\n",
    "train_indices, test_indices = train_test_split(data_clean.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Using the indices to access the text directly from the DataFrame for BERT\n",
    "train_texts = data_clean.loc[train_indices, 'Combined Text'].tolist()\n",
    "test_texts = data_clean.loc[test_indices, 'Combined Text'].tolist()\n",
    "\n",
    "# Proceed with tokenization and dataset preparation as before\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Your label data also needs to be accessed via indices\n",
    "train_labels = data_clean.loc[train_indices, 'Category'].tolist()\n",
    "test_labels = data_clean.loc[test_indices, 'Category'].tolist()\n",
    "\n",
    "# Then, create your dataset for training and testing\n",
    "train_dataset = DealsDataset(train_encodings, train_labels)\n",
    "test_dataset = DealsDataset(test_encodings, test_labels)\n",
    "\n",
    "# Training arguments with optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Increased epochs\n",
    "    per_device_train_batch_size=16,  # Adjusted batch size\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,  # Adjusted warmup steps\n",
    "    weight_decay=0.05,  # Increased weight decay for regularization\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,  # Adjusted learning rate\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training based on loss\n",
    "    evaluation_strategy=\"steps\",  # Evaluate as you go\n",
    "    eval_steps=50,  # How often to run evaluation\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "\n",
    "# Initialize the Trainer with the modified training arguments\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(results)\n",
    "\n",
    "# If you need to calculate more detailed metrics manually:\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predicting on the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset.labels, pred_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(test_dataset.labels, pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Removing HTML tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Removing punctuation\n",
    "    text = text.lower()  # Converting to lower case\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the text data\n",
    "data_clean['Processed Text'] = data_clean['Combined Text'].apply(preprocess_text)\n",
    "\n",
    "# Define a custom dataset for PyTorch\n",
    "class DealsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_len)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Prepare datasets\n",
    "train_texts = data_clean.loc[train_indices, 'Processed Text'].tolist()\n",
    "test_texts = data_clean.loc[test_indices, 'Processed Text'].tolist()\n",
    "train_labels = data_clean.loc[train_indices, 'Category'].tolist()\n",
    "test_labels = data_clean.loc[test_indices, 'Category'].tolist()\n",
    "\n",
    "train_dataset = DealsDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = DealsDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# Define training arguments with some hyperparameter tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,  # Adjust epochs\n",
    "    per_device_train_batch_size=16,  # Adjust batch size\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=3e-5,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=50,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50\n",
    ")\n",
    "\n",
    "# Initialize BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(data_clean['Category'])))\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model on the test dataset to get a summary of the performance\n",
    "evaluation_results = trainer.evaluate(test_dataset)\n",
    "print(\"Evaluation results:\", evaluation_results)\n",
    "\n",
    "# To get predictions and compute detailed accuracy and other metrics\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(test_labels, predicted_labels, target_names=[\"Class1\", \"Class2\", \"Class3\", \"Class4\", \"Class5\"])\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cluster data\n",
    "cluster_file_path = '/Users/aaryanshah/Oncampus-Job/NLP_Gal/clustering/Updated_Clusters _including_CVC_results.csv'\n",
    "clusters_data = pd.read_csv(cluster_file_path)\n",
    "\n",
    "# Display the first few rows and the structure of the dataframe\n",
    "print(clusters_data.head())\n",
    "print(clusters_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
